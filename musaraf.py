# -*- coding: utf-8 -*-
"""musuraf:(prasanna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FlyjZ-wuuYTV7BlivAiQ0rSD9Q1CuvaO
"""

!pip install sentence-transformers faiss-cpu

!pip install sentence-transformers faiss-cpu

import pandas as pd

# Load the dataset
data = pd.DataFrame({
    "question": [
        "What is AI?", "What is Python?", "Who invented the internet?",
        "What is Machine Learning?", "What is the capital of France?",
        "Who wrote 'To Kill a Mockingbird'?", "What is the speed of light?",
        "What is the largest planet in our solar system?",
        "What is the chemical formula for water?", "Who discovered gravity?"
    ],
    "answer": [
        "AI stands for Artificial Intelligence.",
        "Python is a programming language.",
        "The internet was invented by Vint Cerf and Bob Kahn.",
        "Machine Learning is a subset of AI that allows systems to learn from data.",
        "The capital of France is Paris.",
        "The book 'To Kill a Mockingbird' was written by Harper Lee.",
        "The speed of light is approximately 299,792 kilometers per second.",
        "The largest planet in our solar system is Jupiter.",
        "The chemical formula for water is H2O.",
        "Gravity was discovered by Sir Isaac Newton."
    ]
})

# Display the first few rows
data.head()

from sentence_transformers import SentenceTransformer

# Load pre-trained model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Generate embeddings for questions
question_embeddings = model.encode(data['question'].tolist())

# Save the embeddings
import numpy as np
np.save('question_embeddings.npy', question_embeddings)

# Display success message
print("Embeddings generated and saved.")

import faiss

# Load embeddings
question_embeddings = np.load('question_embeddings.npy')

# Create FAISS index
dimension = question_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)  # L2 similarity
index.add(question_embeddings)  # Add embeddings to the index

# Display success message
print(f"FAISS index built with {index.ntotal} entries.")

def chatbot(query):
    # Encode the query
    query_embedding = model.encode([query])[0]

    # Search the FAISS index
    distances, indices = index.search(np.array([query_embedding]), k=1)

    # Retrieve the most relevant answer
    response_index = indices[0][0]
    response = data.iloc[response_index]['answer']

    return response

# Test the chatbot
print(chatbot(input("Enter your query:")))

